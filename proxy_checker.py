import streamlit as st
import asyncio
import aiohttp
from aiohttp_socks import ProxyConnector
import pandas as pd
import time
import datetime
from streamlit_gsheets import GSheetsConnection  # è®°å¾—åœ¨ requirements.txt åŠ è¿™è¡Œ

# 1. é¡µé¢åŸºæœ¬é…ç½®
st.set_page_config(page_title="HamiMelon ç§æœ‰æ£€æµ‹å·¥å…·", layout="wide")

st.title("ğŸ›¡ï¸ SOCKS5 ä»£ç†æ‰¹é‡æ£€æµ‹ (è‡ªåŠ¨åŒæ­¥è‡³ Google Sheets)")
st.info("æ•°æ®å°†å®æ—¶ä¿å­˜è‡³åå°è¡¨æ ¼ã€‚è¯·ç¡®ä¿å·²åœ¨ Secrets ä¸­é…ç½®å¥½å‡­æ®ã€‚")

# 2. åˆå§‹åŒ– Google Sheets è¿æ¥
conn = st.connection("gsheets", type=GSheetsConnection)

# --- æ ¸å¿ƒè§£æé€»è¾‘ ---
def parse_proxy(proxy_str):
    p = proxy_str.strip()
    if not p: return None
    parts = p.split(':')
    if len(parts) == 4:
        ip, port, user, pwd = parts
        return f"socks5://{user}:{pwd}@{ip}:{port}"
    return f"socks5://{p}"

async def fetch_ip_info(session):
    try:
        async with session.get("http://ip-api.com/json/?lang=zh-CN", timeout=10) as resp:
            if resp.status == 200:
                return await resp.json()
    except:
        return None
    return None

async def check_single_proxy(raw_proxy, semaphore, test_url, timeout):
    async with semaphore:
        formatted_url = parse_proxy(raw_proxy)
        if not formatted_url: return None
        
        start_time = time.time()
        try:
            connector = ProxyConnector.from_url(formatted_url)
            async with aiohttp.ClientSession(connector=connector) as session:
                info = await fetch_ip_info(session)
                latency = int((time.time() - start_time) * 1000)
                
                if info and info.get("status") == "success":
                    return {
                        "åŸå§‹åœ°å€": raw_proxy,
                        "çŠ¶æ€": "âœ… æˆåŠŸ",
                        "å»¶è¿Ÿ": f"{latency}ms",
                        "å‡ºå£ IP": info.get("query"),
                        "å›½å®¶/åœ°åŒº": f"{info.get('country')} - {info.get('city')}",
                        "è¿è¥å•†": info.get("isp")
                    }
        except:
            pass
        return {"åŸå§‹åœ°å€": raw_proxy, "çŠ¶æ€": "âŒ å¤±è´¥", "å»¶è¿Ÿ": "-", "å‡ºå£ IP": "-", "å›½å®¶/åœ°åŒº": "-", "è¿è¥å•†": "-"}

async def run_checks(proxies, max_concurrency, test_url, timeout):
    semaphore = asyncio.Semaphore(max_concurrency)
    tasks = [check_single_proxy(p, semaphore, test_url, timeout) for p in proxies]
    return await asyncio.gather(*tasks)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("è®¾ç½®")
    test_url = st.text_input("æµ‹è¯•åœ°å€", value="http://www.google.com/generate_204")
    timeout = st.slider("è¶…æ—¶ (ç§’)", 1, 30, 15)
    max_c = st.number_input("å¹¶å‘æ•°", 1, 100, 20)

# --- ä¸»ç•Œé¢ ---
input_text = st.text_area("ç²˜è´´ä»£ç†åˆ—è¡¨ (IP:Port:User:Pass)", height=200)

if st.button("ğŸš€ å¼€å§‹æ‰¹é‡æ£€æµ‹å¹¶ä¿å­˜", type="primary"):
    proxies = [p.strip() for p in input_text.split('\n') if p.strip()]
    if not proxies:
        st.warning("è¯·è¾“å…¥ä»£ç†åœ°å€")
    else:
        with st.spinner("æ­£åœ¨æ£€æµ‹å¹¶